{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6259a98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dishplace is located in sunnyvale downtown the...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>service can be slower during busy hours but ou...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>portions are huge both french toast and their ...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we started with apps going the chicken and waf...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the biscuits and gravy was too salty two peopl...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paragraph category\n",
       "0  dishplace is located in sunnyvale downtown the...     food\n",
       "1  service can be slower during busy hours but ou...     food\n",
       "2  portions are huge both french toast and their ...     food\n",
       "3  we started with apps going the chicken and waf...     food\n",
       "4  the biscuits and gravy was too salty two peopl...     food"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../Data/lstm.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c957107b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   paragraph  20 non-null     object\n",
      " 1   category   20 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 448.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0549d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['food', 'sports'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b52eac",
   "metadata": {},
   "source": [
    "> food와 sports로만 구성되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e17e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paragraph에 사용된 중복없는 전체 단어 갯수를 파악\n",
    "results = set()\n",
    "df['paragraph'].str.lower().str.split().apply(results.update)\n",
    "vocab_size = len(results)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9da75a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "# 데이터에서 가장 긴 문장의 단어 갯수를 확인\n",
    "max_length = 0\n",
    "for row in df['paragraph']:\n",
    "    if len(row.split(\" \")) > max_length:\n",
    "        max_length = len(row.split(\" \"))\n",
    "\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c354722e",
   "metadata": {},
   "source": [
    "#### 단어를 숫자로 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cfc0e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dishplace is located in sunnyvale downtown there is parking around the area but it can be difficult to find during peak business hours my sisters and i came to this place for dinner on a weekday they were really busy so i highly recommended making reservations unless you have the patience to wait',\n",
       " 'service can be slower during busy hours but our waiter was courteous and help gave some great entree recommendations',\n",
       " 'portions are huge both french toast and their various omelettes are really good their french toast is probably 1.5x more than other brunch places great place to visit if you are hungry and dont want to wait 1 hour for a table',\n",
       " 'we started with apps going the chicken and waffle slides and chicken nachos the sliders were amazing and the nachos were good too maybe by themselves the nachos would have scored better but after those sliders they were up against some tough competition',\n",
       " 'the biscuits and gravy was too salty two people in my group had the gravy and all thought it was too salty my hubby ordered a side of double egg and it was served on two small plates who serves eggs to one person on separate plates we commented on that when it was delivered and even the server laughed and said she doesnt know why the kitchen does that presentation of food is important and they really missed on this one',\n",
       " 'the garlic fries were a great starter (and a happy hour special) the pancakes looked and tasted great and were a fairly generous portion',\n",
       " 'our meal was excellent i had the pasta ai formaggi which was so rich i didnt dare eat it all although i certainly wanted to excellent flavors with a great texture contrast between the soft pasta and the crisp bread crumbs too much sauce for me but a wonderful dish',\n",
       " 'what i enjoy most about palo alto is so many restaurants have dog-friendly seating outside i had bookmarked italico from when they first opened about a 1.5 years ago and was jonesing for some pasta so time to finally knock that bookmark off',\n",
       " 'the drinks came out fairly quickly a good two to three minutes after the orders were taken i expected my iced tea to taste a bit more sweet but this was straight up green tea with ice in it not to complain of course but i was pleasantly surprised',\n",
       " 'despite the not so good burger the service was so slow the restaurant wasnt even half full and they took very long from the moment we got seated to the time we left it was almost 2 hours we thought that it would be quick since we ordered as soon as we sat down my coworkers did seem to enjoy their beef burgers for those who eat beef however i will not be returning it is too expensive and extremely slow service',\n",
       " 'the four reigning major champions simona halep caroline wozniacki angelique kerber and defending us open champion sloane stephens could make a case for being the quartet most likely to succeed especially as all but stephens has also enjoyed the no1 ranking within the last 14 months as they prepare for their gruelling new york campaigns they currently hold the top four places in the ranks',\n",
       " 'the briton was seeded nn7 here last year before a slump in form and confidence took her down to no46 after five first-round losses but there have been signs of a turnaround including a victory over a sub-par serena williams in san jose plus wins against jelena ostapenko and victoria azarenka in montreal. konta pulled out of new haven this week with illness but will hope for good things where she first scored wins in a major before her big breakthroughs to the semis in australia and wimbledon',\n",
       " 'stephens surged her way back from injury in stunning style to win her first major here last year—and ranked just no83 she has since proved what a big time player she is winning the miami title via four fellow major champions then reaching the final at the french open back on north american hard courts she ran to the final in montreal only just edged out by halep she has also avoided many of the big names in her quarter—except for wild card azarenka as a possible in the third round',\n",
       " 'when it came to england chances in the world cup it would be fair to say that most fans had never been more pessimistic than they were this year after enduring years of truly dismal performances at major tournaments – culminating in the 2014 event where they failed to win any of their three group games and finished in bottom spot those results led to the resignation of manager roy hodgson',\n",
       " 'the team that eliminated russia – croatia – also improved enormously during the tournament before it began their odds were 33/1 but they played with real flair and star players like luka modric ivan rakitic and ivan perisic showed their quality on the world stage having displayed their potential by winning all three of their group stage games croatia went on to face difficult tests like the semi-final against england',\n",
       " 'the perseyside outfit finished in fourth place in the premier league table and without a trophy last term after having reached the champions league final before losing to real madrid',\n",
       " 'liverpool fc will return to premier league action on saturday lunchtime when they travel to leicester city in the top flight as they look to make it four wins in a row in the league',\n",
       " 'alisson signed for liverpool fc from as roma this summer and the brazilian goalkeeper has helped the reds to keep three clean sheets in their first three premier league games',\n",
       " 'but the rankings during that run-in to new york hid some very different undercurrents for murray had struggled with a hip injury since the clay swing and had not played a match since losing his quarter-final at wimbledon and he would pull out of the us open just two days before the tournament began—too late however to promote nederer to the no2 seeding',\n",
       " 'then came the oh-so-familiar djokovic-nadal no-quarter-given battle for dominance in the third set there were exhilarating rallies with both chasing to the net both retrieving what looked like winning shots nadal more than once pulled off a reverse smash and had his chance to seal the tie-break but it was djokovic serving at 10-9 who dragged one decisive error from nadal for a two-sets lead']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs = df['paragraph'].to_list()\n",
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f821cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "keras.utils.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9551f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[421, 32, 309, 45, 9, 46, 375, 32, 308, 20, 128, 306, 226, 444, 111, 513, 411, 453, 49, 408, 335, 198, 189, 115, 400, 300, 113, 237, 453, 516, 283, 160, 218, 82, 441, 430, 224, 271, 323, 105, 138, 113, 395, 341, 91, 530, 76, 456, 388, 128, 137, 453, 392], [386, 111, 513, 490, 408, 105, 189, 226, 421, 381, 144, 179, 300, 170, 7, 425, 346, 212, 255], [466, 280, 130, 39, 463, 360, 300, 382, 234, 125, 280, 323, 83, 382, 463, 360, 32, 182, 421, 100, 467, 103, 496, 489, 80, 346, 283, 453, 388, 285, 456, 280, 438, 300, 280, 208, 453, 392, 421, 130, 160, 441, 432], [397, 74, 120, 397, 444, 128, 344, 300, 4, 389, 300, 344, 125, 128, 424, 271, 444, 300, 128, 125, 271, 83, 7, 293, 100, 385, 128, 125, 375, 388, 222, 414, 226, 152, 228, 424, 224, 271, 469, 346, 425, 434, 429], [128, 279, 300, 35, 144, 7, 306, 412, 219, 45, 115, 396, 444, 128, 35, 300, 137, 302, 444, 144, 7, 306, 115, 381, 207, 441, 467, 260, 506, 421, 300, 444, 144, 154, 82, 412, 199, 252, 22, 484, 482, 453, 169, 95, 82, 74, 252, 397, 28, 82, 174, 13, 444, 144, 233, 300, 440, 128, 232, 234, 300, 262, 262, 233, 88, 349, 128, 146, 219, 174, 83, 260, 105, 32, 241, 300, 224, 323, 491, 82, 516, 169], [128, 210, 485, 271, 441, 346, 61, 300, 441, 265, 130, 495, 128, 366, 218, 300, 490, 346, 300, 271, 441, 131, 396, 349], [421, 18, 144, 149, 113, 444, 128, 242, 17, 254, 361, 144, 138, 368, 113, 24, 444, 170, 444, 137, 29, 113, 507, 204, 453, 149, 94, 120, 441, 346, 45, 522, 484, 128, 57, 242, 300, 128, 312, 197, 305, 7, 444, 69, 160, 520, 226, 441, 45, 382], [99, 113, 158, 350, 356, 514, 257, 32, 138, 77, 520, 388, 437, 354, 498, 502, 113, 444, 199, 135, 66, 13, 224, 257, 133, 356, 441, 421, 507, 454, 87, 300, 144, 62, 160, 425, 242, 138, 325, 453, 401, 316, 174, 67, 478], [128, 411, 237, 439, 131, 476, 441, 83, 412, 453, 29, 308, 152, 128, 318, 271, 511, 113, 404, 115, 3, 495, 453, 405, 441, 63, 467, 300, 226, 516, 144, 352, 469, 77, 495, 120, 250, 45, 444, 118, 453, 280, 260, 407, 226, 113, 144, 8, 44], [394, 128, 118, 138, 83, 304, 128, 386, 144, 138, 500, 128, 209, 12, 440, 168, 371, 300, 224, 100, 422, 28, 66, 128, 300, 397, 379, 412, 453, 128, 325, 397, 56, 444, 144, 105, 179, 189, 397, 302, 174, 444, 375, 513, 447, 414, 397, 207, 454, 429, 454, 397, 533, 298, 115, 465, 240, 194, 453, 158, 382, 141, 43, 160, 228, 22, 170, 141, 291, 113, 41, 118, 513, 238, 444, 32, 7, 238, 300, 146, 500, 386], [128, 530, 43, 465, 487, 246, 301, 419, 466, 326, 505, 300, 427, 195, 206, 129, 168, 377, 36, 238, 441, 233, 160, 491, 128, 376, 350, 327, 453, 451, 11, 454, 137, 226, 377, 145, 13, 365, 128, 314, 248, 57, 128, 426, 426, 53, 454, 224, 257, 160, 382, 452, 303, 354, 464, 224, 266, 65, 128, 519, 530, 80, 45, 128, 288], [128, 106, 144, 307, 40, 94, 426, 41, 313, 441, 392, 45, 277, 300, 498, 100, 72, 298, 453, 171, 152, 27, 257, 445, 405, 226, 375, 388, 136, 179, 260, 441, 148, 287, 441, 168, 472, 441, 388, 397, 449, 223, 45, 528, 362, 528, 59, 346, 234, 334, 300, 335, 166, 45, 434, 300, 92, 439, 260, 303, 510, 516, 461, 120, 177, 226, 41, 252, 160, 83, 291, 485, 262, 257, 222, 59, 45, 441, 465, 313, 72, 180, 223, 453, 128, 528, 45, 326, 300, 112], [377, 85, 72, 49, 176, 66, 244, 45, 295, 522, 453, 289, 72, 257, 465, 94, 426, 123, 346, 371, 450, 262, 145, 414, 498, 99, 441, 180, 325, 320, 262, 32, 489, 128, 126, 405, 279, 530, 316, 465, 487, 159, 233, 128, 320, 315, 128, 463, 206, 176, 82, 398, 499, 454, 366, 262, 237, 453, 128, 320, 45, 434, 528, 371, 228, 439, 100, 301, 262, 145, 13, 452, 77, 260, 128, 180, 380, 45, 72, 57, 160, 304, 89, 166, 454, 441, 305, 45, 128, 348, 445], [13, 444, 237, 453, 207, 485, 45, 128, 339, 96, 444, 375, 513, 500, 453, 128, 174, 350, 410, 444, 259, 136, 467, 379, 103, 224, 271, 516, 41, 152, 307, 454, 260, 393, 371, 136, 315, 465, 383, 455, 272, 45, 128, 239, 142, 485, 224, 75, 453, 289, 133, 260, 382, 29, 396, 29, 300, 467, 45, 301, 54, 228, 238, 162, 453, 128, 72, 260, 460, 329, 38], [128, 447, 174, 131, 285, 455, 491, 455, 13, 252, 245, 408, 128, 253, 313, 444, 343, 382, 123, 271, 67, 421, 226, 224, 264, 120, 67, 425, 300, 508, 230, 230, 191, 344, 438, 84, 300, 438, 199, 406, 382, 122, 82, 128, 339, 236, 144, 172, 382, 499, 100, 489, 137, 29, 260, 382, 396, 236, 29, 491, 305, 82, 453, 221, 411, 283, 230, 128, 370, 320, 346, 207], [128, 23, 388, 467, 45, 447, 283, 45, 128, 251, 172, 432, 300, 304, 441, 207, 426, 198, 152, 144, 369, 128, 487, 172, 320, 313, 190, 453, 67, 181], [144, 506, 41, 134, 453, 251, 172, 505, 82, 17, 449, 13, 224, 266, 453, 154, 383, 45, 128, 519, 434, 454, 224, 434, 453, 238, 444, 530, 59, 45, 441, 441, 45, 128, 172], [422, 52, 160, 144, 506, 66, 454, 34, 516, 244, 300, 128, 94, 196, 145, 39, 128, 240, 453, 334, 29, 227, 457, 45, 382, 257, 29, 251, 172, 29], [226, 128, 175, 408, 174, 118, 45, 453, 303, 354, 366, 425, 422, 208, 88, 160, 238, 444, 5, 120, 441, 67, 244, 414, 128, 175, 67, 300, 444, 118, 264, 441, 83, 414, 190, 310, 411, 320, 315, 112, 300, 472, 375, 283, 439, 260, 128, 195, 206, 371, 412, 481, 313, 128, 253, 153, 400, 291, 453, 244, 487, 453, 128, 466, 264], [159, 237, 128, 101, 138, 279, 437, 415, 2, 411, 397, 512, 160, 434, 45, 128, 348, 22, 375, 271, 90, 500, 120, 39, 244, 453, 128, 443, 39, 385, 99, 218, 230, 489, 240, 415, 467, 103, 346, 92, 478, 441, 306, 298, 300, 444, 310, 155, 453, 74, 128, 500, 500, 226, 444, 144, 437, 180, 315, 146, 520, 22, 180, 169, 412, 528, 66, 415, 160, 441, 412, 409, 530]]\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding\n",
    "encoded_paragraphs = [keras.preprocessing.text.one_hot(paragraph, vocab_size) \\\n",
    "                    for paragraph in paragraphs]\n",
    "print(encoded_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc5dd3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[421,  32, 309, ...,   0,   0,   0],\n",
       "       [386, 111, 513, ...,   0,   0,   0],\n",
       "       [466, 280, 130, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [422,  52, 160, ...,   0,   0,   0],\n",
       "       [226, 128, 175, ...,   0,   0,   0],\n",
       "       [159, 237, 128, ...,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장마다 단어 갯수가 다르므로, 시퀀스패딩을 넣어서 문자의 길이를 동일하게 맞춘다.\n",
    "padded_paragraphs_encodging = keras.preprocessing.sequence.pad_sequences(\\\n",
    "                                    encoded_paragraphs,\n",
    "                                    maxlen=max_length,\n",
    "                                    padding = 'post'\n",
    "\n",
    ")\n",
    "\n",
    "padded_paragraphs_encodging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db54b13",
   "metadata": {},
   "source": [
    "#### 분류 항목(food, sports)를 수치로 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1432f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df['category'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3c35147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_encode(category):\n",
    "    if category == \"food\":\n",
    "        return [1,0]\n",
    "    else:\n",
    "        return [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "445da6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_category = [category_encode(category) for category in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85cf1807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0], [1, 0], [1, 0], [1, 0], [1, 0]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_category[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5575c715",
   "metadata": {},
   "source": [
    "#### Feature 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a47aca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[421, 32, 309, 45, 9, 46, 375, 32, 308, 20, 128, 306, 226, 444, 111, 513, 411, 453, 49, 408, 335, 198, 189, 115, 400, 300, 113, 237, 453, 516, 283, 160, 218, 82, 441, 430, 224, 271, 323, 105, 138, 113, 395, 341, 91, 530, 76, 456, 388, 128, 137, 453, 392]\n",
      "[159, 237, 128, 101, 138, 279, 437, 415, 2, 411, 397, 512, 160, 434, 45, 128, 348, 22, 375, 271, 90, 500, 120, 39, 244, 453, 128, 443, 39, 385, 99, 218, 230, 489, 240, 415, 467, 103, 346, 92, 478, 441, 306, 298, 300, 444, 310, 155, 453, 74, 128, 500, 500, 226, 444, 144, 437, 180, 315, 146, 520, 22, 180, 169, 412, 528, 66, 415, 160, 441, 412, 409, 530]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_paragraphs[0])\n",
    "print(encoded_paragraphs[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5b4b33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[421  32 309  45   9  46 375  32 308  20 128 306 226 444 111 513 411 453\n",
      "  49 408 335 198 189 115 400 300 113 237 453 516 283 160 218  82 441 430\n",
      " 224 271 323 105 138 113 395 341  91 530  76 456 388 128 137 453 392   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "[159 237 128 101 138 279 437 415   2 411 397 512 160 434  45 128 348  22\n",
      " 375 271  90 500 120  39 244 453 128 443  39 385  99 218 230 489 240 415\n",
      " 467 103 346  92 478 441 306 298 300 444 310 155 453  74 128 500 500 226\n",
      " 444 144 437 180 315 146 520  22 180 169 412 528  66 415 160 441 412 409\n",
      " 530   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n"
     ]
    }
   ],
   "source": [
    "print(padded_paragraphs_encodging[0])\n",
    "print(padded_paragraphs_encodging[19])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f91e0e8",
   "metadata": {},
   "source": [
    "#### 주제를 분류하는 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "441947bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# 문맥 생성 단계\n",
    "model.add(keras.layers.Embedding(vocab_size, 5))\n",
    "model.add(keras.layers.LSTM(64))\n",
    "\n",
    "# 분류 단계\n",
    "model.add(keras.layers.Dense(\n",
    "                32,\n",
    "                activation='relu'\n",
    "))\n",
    "\n",
    "model.add(keras.layers.Dense(\n",
    "                2,\n",
    "                activation='softmax'\n",
    "))\n",
    "\n",
    "model.build(input_shape=(None, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1977d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer = 'adam',\n",
    "        metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8521174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature와 Target의 Type 변경\n",
    "import numpy as np\n",
    "train_X = np.array(padded_paragraphs_encodging)\n",
    "train_y = np.array(encoded_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "604c9793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3500 - loss: 0.6946\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5500 - loss: 0.6927\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5500 - loss: 0.6920\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6000 - loss: 0.6914\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6000 - loss: 0.6909\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6000 - loss: 0.6903\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6000 - loss: 0.6897\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6000 - loss: 0.6888\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6000 - loss: 0.6874\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6000 - loss: 0.6853\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6000 - loss: 0.6812\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6000 - loss: 0.6714\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8500 - loss: 0.6443\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.6001\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7000 - loss: 0.5210\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9500 - loss: 0.3107\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9500 - loss: 0.2131\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9500 - loss: 0.2012\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9500 - loss: 0.1922\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9500 - loss: 0.1861\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9500 - loss: 0.1816\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9500 - loss: 0.1772\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9500 - loss: 0.1740\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9500 - loss: 0.1717\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9500 - loss: 0.1703\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9500 - loss: 0.1696\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9000 - loss: 0.2864\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9500 - loss: 0.1709\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9500 - loss: 0.1713\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9500 - loss: 0.1712\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9500 - loss: 0.1707\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9500 - loss: 0.1698\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9500 - loss: 0.1688\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9500 - loss: 0.1680\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9500 - loss: 0.1674\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9500 - loss: 0.1671\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9500 - loss: 0.1671\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9500 - loss: 0.1673\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9500 - loss: 0.1675\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9500 - loss: 0.1678\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9500 - loss: 0.1680\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9500 - loss: 0.1681\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9500 - loss: 0.1682\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9500 - loss: 0.1682\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9500 - loss: 0.1681\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9500 - loss: 0.1681\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9500 - loss: 0.1680\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9500 - loss: 0.1680\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9500 - loss: 0.1679\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9500 - loss: 0.1679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20bf9e1b670>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    batch_size=10,\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2afc166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9500 - loss: 0.1674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1673724353313446, 0.949999988079071]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e0011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
